{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet"
      ],
      "metadata": {
        "id": "GsR29szqoW5p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCKo5LL9oQZG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array"
      ],
      "metadata": {
        "id": "_12q5WxRorM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet import preprocess_input"
      ],
      "metadata": {
        "id": "PW_oLTvRosWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet import decode_predictions"
      ],
      "metadata": {
        "id": "_PuZ42dMosL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50"
      ],
      "metadata": {
        "id": "huveYhvHosBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = load_img('/content/Tulip.jpg', target_size=(224, 224))"
      ],
      "metadata": {
        "id": "Ukvaz8Gsoryr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = img_to_array(image)\n"
      ],
      "metadata": {
        "id": "21bMXQRZqPzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n"
      ],
      "metadata": {
        "id": "zVuyMwl6qPvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = preprocess_input(image)\n"
      ],
      "metadata": {
        "id": "VADX-reUqPtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMTfuC2hqPqj",
        "outputId": "d86ccaa5-88eb-4c75-c1d5-d0730f7ec809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUY0s95Uqk4V",
        "outputId": "80413891-35ce-4618-89e7-fce468e671c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode_predictions(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvzhsQ0Eqkr2",
        "outputId": "0cd10c77-4e17-464a-a3c9-10ddb25e488a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n03457902', 'greenhouse', 0.538782),\n",
              "  ('n02793495', 'barn', 0.09291202),\n",
              "  ('n03891251', 'park_bench', 0.059755262),\n",
              "  ('n13133613', 'ear', 0.044442818),\n",
              "  ('n11879895', 'rapeseed', 0.043648023)]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG16"
      ],
      "metadata": {
        "id": "eo9Mm7WirFNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "from tensorflow.keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "TmQrdVs3rF1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = load_img('/content/Tulip.jpg', target_size=(224, 224))\n",
        "\n",
        "image = img_to_array(image)\n",
        "\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "image = preprocess_input(image)\n",
        "\n",
        "model = VGG16()\n",
        "\n",
        "yhat = model.predict(image)\n",
        "\n",
        "decode_predictions(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa1tdgbXrGxg",
        "outputId": "2df720dc-c87e-4f92-bd81-45741342733f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 3s 0us/step\n",
            "1/1 [==============================] - 1s 555ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n03930313', 'picket_fence', 0.1863425),\n",
              "  ('n02793495', 'barn', 0.15566453),\n",
              "  ('n04604644', 'worm_fence', 0.13186546),\n",
              "  ('n03891251', 'park_bench', 0.05552704),\n",
              "  ('n03207743', 'dishrag', 0.043337043)]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG19\n"
      ],
      "metadata": {
        "id": "tbxLmYwEr4nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import decode_predictions\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19"
      ],
      "metadata": {
        "id": "Rxw0cg-brGuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = load_img('/content/Tulip.jpg', target_size=(224, 224))\n",
        "\n",
        "image = img_to_array(image)\n",
        "\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "image = preprocess_input(image)\n",
        "\n",
        "model = VGG19()\n",
        "\n",
        "yhat = model.predict(image)\n",
        "\n",
        "decode_predictions(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu2Ot6x9rGr7",
        "outputId": "f27a5015-254c-4ba4-e5f0-a89560a45e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574710816/574710816 [==============================] - 3s 0us/step\n",
            "1/1 [==============================] - 1s 682ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n03388043', 'fountain', 0.4386335),\n",
              "  ('n03930313', 'picket_fence', 0.22129704),\n",
              "  ('n03733281', 'maze', 0.05377549),\n",
              "  ('n04604644', 'worm_fence', 0.05153386),\n",
              "  ('n12985857', 'coral_fungus', 0.028797371)]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mobile Net"
      ],
      "metadata": {
        "id": "hbMv7384su8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "import keras\n",
        "\n",
        "from keras.applications import imagenet_utils\n",
        "\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "HM2RfvmxrGpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNet\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "mobile =keras.applications.mobilenet.MobileNet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCVcsEX4rGnE",
        "outputId": "4106a508-da5a-4bcd-f6cf-66779830a5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ],
      "metadata": {
        "id": "WmguCGtWrGkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename='/content/Tulip.jpg')\n",
        "\n",
        "preprocessed_image = prepare_image('/content/Tulip.jpg')\n",
        "\n",
        "predictions = mobile.predict(preprocessed_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v99SpQYfrGiV",
        "outputId": "a7f32182-0b70-483d-8f96-cbcf9924f527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 408ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = imagenet_utils.decode_predictions(predictions)\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf5SmCPPrGbO",
        "outputId": "998805c6-9c40-424e-bff8-07c95136af0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n04326547', 'stone_wall', 0.7179952),\n",
              "  ('n04604644', 'worm_fence', 0.11733208),\n",
              "  ('n03457902', 'greenhouse', 0.04277872),\n",
              "  ('n03944341', 'pinwheel', 0.033714607),\n",
              "  ('n11879895', 'rapeseed', 0.019201688)]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}